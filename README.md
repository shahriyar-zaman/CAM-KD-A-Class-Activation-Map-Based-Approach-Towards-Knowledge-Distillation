
# CAM-KD: Class Activation Map-Based Knowledge Distillation

## Project Overview

**CAM-KD** is a method for compressing large neural networks by transferring knowledge from a larger **teacher model** to a smaller **student model** using **Class Activation Maps (CAMs)**. This approach improves both model performance and transparency by showing which regions of the image contribute to the modelâ€™s predictions.

### Key Features:
- **Improved Model Accuracy**: Achieved 68.3% accuracy on CIFAR10 using CAM-based distillation, outperforming traditional methods.
- **Explainability**: CAMs provide insights into the decision-making process of both teacher and student models.
- **Efficient Student Model**: The custom **CAM-Net** student model has only 0.096 million parameters, making it highly efficient for deployment on resource-constrained devices.

## How It Works

1. **Knowledge Distillation**: The student model learns from the teacher model by mimicking its predictions. In our approach, CAMs are also used to transfer the structural knowledge.
2. **Class Activation Maps (CAMs)**: CAMs highlight important regions of an image for classification. During training, we compare the CAMs of the teacher and student and minimize the difference between them.
3. **Distillation Process**: We combine the CAM loss with traditional distillation loss to guide the student model to learn both high-level predictions and low-level visual features.

## Experiments and Results

- **Dataset**: We used the **CIFAR10** dataset with 60,000 32x32 images across 10 classes.
- **Teacher Model**: ResNet-50 (27.8M parameters)
- **Student Model**: CAM-Net (0.096M parameters)
- **Best Accuracy**: The student model reached 68.3% accuracy by combining CAM and distillation losses, outperforming the baseline approach (67.2%).

### Result Visualizations

Below is a comparison of the **Class Activation Maps** generated by the teacher and student models after training with CAM-based distillation. The red regions show where the models focus when classifying the images.

![CAM Results](path/to/your/image.png)

*(Replace "path/to/your/image.png" with the actual path to your image in the repository)*

## Installation

Follow these steps to set up and run the code:

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/CAM-KD.git
   cd CAM-KD
   ```

2. Install the required Python libraries:
   ```bash
   pip install -r requirements.txt
   ```

3. Train the student model using the CAM-KD method:
   ```bash
   python train.py
   ```

## Usage

- **Train Teacher Model**: First, train your teacher model (e.g., ResNet-50):
   ```bash
   python train_teacher.py --dataset cifar10 --model resnet50
   ```

- **Distill Knowledge to Student Model**: Use the teacher model to train the student model with CAM-based distillation:
   ```bash
   python distill.py --dataset cifar10 --teacher resnet50 --student cam-net
   ```

- **View Results**: Check the accuracy and visual explanations (CAM heatmaps) during training to evaluate how well the student model learns from the teacher.

